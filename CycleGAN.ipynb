{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "bc355208268fddd43ceef5b0d1bc4fbbe6a8a03a75d7443701572e97a740f9c2"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as trForms\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "source": [
    "## Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root = \"\", transform = None, model = \"train\"):\n",
    "        super(ImageDataset, self).__init__()\n",
    "        self.transform = trForms.Compose(transform)\n",
    "        # 两组图片 每个sample是一个pair apple-orange\n",
    "        self.pathA = os.path.join(root, model,\"A/*\")   # 所有的训练苹果图片路径 root/train/A/*\n",
    "        self.pathB = os.path.join(root, model, \"B/*\")  # 所有orange\n",
    "        self.listA = glob.glob(self.pathA)\n",
    "        self.listB = glob.glob(self.pathB)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        im_pathA = self.listA[index % len(self.listA)]\n",
    "        im_pathB = random.choice(self.listB)\n",
    "\n",
    "        im_A = Image.open(im_pathA)  # 从路径中读取图片\n",
    "        im_B = Image.open(im_pathB)\n",
    "\n",
    "        im_A = self.transform(im_A)\n",
    "        im_B = self.transform(im_B)\n",
    "        return {\"A\": im_A, \"B\":im_B}\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(len(self.listA), len(self.listB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/data/zhuowei/datasets/cyclegan/datasets/apple2orange\""
   ]
  },
  {
   "source": [
    "图片resize, 插值方式为BILINEAR"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [trForms.Resize(256, Image.BILINEAR), trForms.ToTensor()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(ImageDataset(root=root, transform=transforms, model=\"train\"), shuffle=True, batch_size=1, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    print(batch[\"A\"].shape)\n",
    "    break"
   ]
  },
  {
   "source": [
    "# Model: CycleGAN\n",
    "\n",
    "主干网络采用ResNet"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class resBlock(nn.Module):\n",
    "    def __init__(self, in_channel):\n",
    "        super(resBlock, self).__init__()\n",
    "        conv_block = [\n",
    "            nn.ReflectionPad2d(1),  # 对输入扩边，上下左右扩展一行一列,填充内容来自输入   避免卷积之后图像尺寸损失\n",
    "            nn.Conv2d(in_channels=in_channel, out_channels= in_channel, kernel_size=3),\n",
    "            nn.InstanceNorm2d(in_channel),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(in_channels=in_channel, out_channels= in_channel, kernel_size=3),\n",
    "            nn.InstanceNorm2d(in_channel)\n",
    "        ]\n",
    "\n",
    "        self.conv_block = nn.Sequential(*conv_block) # 串联算子\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return x + self.conv_block(x)  # 跳连结构"
   ]
  },
  {
   "source": [
    "## Generator"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        # 第一个卷积采用一个7*7的大卷积核\n",
    "        net = [\n",
    "            nn.ReflectionPad2d(3),  # 图像先pad3后在经过7*7的卷积核，卷积结果的shape不变\n",
    "            nn.Conv2d(3,64,7),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ] # 输出64 * 256 * 256\n",
    "\n",
    "        # downsampling\n",
    "        in_channel = 64\n",
    "        out_channel = in_channel * 2\n",
    "        for _ in range(2):\n",
    "            net += [\n",
    "                nn.Conv2d(in_channels=in_channel, out_channels = out_channel, kernel_size=3, stride=2, padding=1),\n",
    "                nn.InstanceNorm2d(64),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            in_channel = out_channel\n",
    "            out_channel = in_channel * 2\n",
    "        \n",
    "        # resBlock:\n",
    "        for _ in range(9):\n",
    "            net += [resBlock(in_channel)]\n",
    "\n",
    "\n",
    "        # upsampling:\n",
    "        out_channel = in_channel // 2\n",
    "        for _ in range(2):\n",
    "            net += [nn.ConvTranspose2d(in_channel, out_channel, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                    nn.InstanceNorm2d(out_channel),\n",
    "                    nn.ReLU(inplace = True)\n",
    "                    ]\n",
    "            in_channel = out_channel\n",
    "            out_channel = in_channel //2\n",
    "\n",
    "\n",
    "        # output:\n",
    "        net += [\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(in_channel, 3, 7),\n",
    "            nn.Tanh()\n",
    "        ]\n",
    "        self.model = nn.Sequential(*net)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "source": [
    "## Discriminator"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator,self).__init__()\n",
    "        model = [nn.Conv2d(3,64,4,stride = 2,padding = 1),\n",
    "                 nn.LeakyReLU(.2, inplace=True)\n",
    "                ]        \n",
    "        model += [nn.Conv2d(64,128,4,stride = 2,padding = 1),\n",
    "                 nn.InstanceNorm2d(128),\n",
    "                 nn.LeakyReLU(.2, inplace=True)\n",
    "                ]\n",
    "        model += [nn.Conv2d(128,256,4,stride = 2,padding = 1),\n",
    "                 nn.InstanceNorm2d(256),\n",
    "                 nn.LeakyReLU(.2, inplace=True)\n",
    "                ]\n",
    "\n",
    "        model += [nn.Conv2d(256,512,4,stride = 2,padding = 1),\n",
    "                 nn.InstanceNorm2d(512),\n",
    "                 nn.LeakyReLU(.2, inplace=True)\n",
    "                ]\n",
    "        model += [nn.Conv2d(512,1,4, padding=1)]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "\n",
    "        return F.avg_pool2d(x, x.size()[2:]).view(x.size()[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator()\n",
    "D = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.ones((1,3,256,256), dtype = torch.float)\n",
    "out = G(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "out = D(input_tensor)\n",
    "print(out.shape)"
   ]
  },
  {
   "source": [
    "# Train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import tensor2image, LambdaLR, weights_init_normal, ReplayBuffer\n",
    "import itertools\n",
    "import tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "size = 256\n",
    "lr = 0.0002\n",
    "n_epochs = 200\n",
    "epoch = 0\n",
    "decay_epoch = 100\n",
    "\n",
    "# network\n",
    "netG_A2B = Generator().to(device)\n",
    "netG_B2A = Generator().to(device)\n",
    "netD_A = Discriminator().to(device)\n",
    "netD_B = Discriminator().to(device)\n",
    "\n",
    "# loss\n",
    "loss_GAN = torch.nn.MSELoss()\n",
    "loss_Cycle = torch.nn.L1Loss()\n",
    "loss_identity = torch.nn.L1Loss()  # 真实数据和生成数据相似程度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer & LR\n",
    "opt_G = torch.optim.Adam(itertools.chain(netG_A2B.parameters(), netG_B2A.parameters()), lr = lr, betas=(0.5,0.9999))  # 两个生成器的参数连接 同时优化\n",
    "\n",
    "optD_A = torch.optim.Adam(netD_A.parameters(), lr = lr, betas = (0.5,0.9999))\n",
    "optD_B = torch.optim.Adam(netD_B.parameters(), lr = lr, betas = (0.5, 0.9999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义学习率衰减\n",
    "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(opt_G, \n",
    "                                                   lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)\n",
    "\n",
    "lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optD_A, \n",
    "                                                   lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)\n",
    "\n",
    "lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optD_B, \n",
    "                                                   lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = root\n",
    "input_A = torch.ones([1,3,size,size], dtype = torch.float).to(device)\n",
    "input_B = torch.ones([1,3,size,size], dtype = torch.float).to(device)\n",
    "label_real = torch.ones([1], dtype = torch.float, requires_grad = False).to(device)\n",
    "label_fake = torch.zeros([1], dtype = torch.float, requires_grad = False).to(device)\n",
    "\n",
    "fake_A_buffer = ReplayBuffer()\n",
    "fake_B_buffer = ReplayBuffer()\n",
    "\n",
    "log_path = \"logs\"\n",
    "write_log = tensorboardX.SummaryWriter(log_path)  # 写入对应路径\n",
    "\n",
    "transform_ = [\n",
    "    trForms.Resize(int(256 * 1.12), Image.BICUBIC),  #尺寸放大\n",
    "    trForms.RandomCrop(256),  # 随机剪裁到256\n",
    "    trForms.RandomHorizontalFlip(),\n",
    "    trForms.ToTensor(),\n",
    "    trForms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(ImageDataset(root, transform_, model =\"train\"), batch_size = batch_size, shuffle = True, num_workers = 8)\n",
    "\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3855 \n",
      "epoch: 4, loss G: 12.825312614440918, loss_G_identity: 2.023472309112549, loss_G_GAN: 0.28446170687675476, loss_G_cycle: 10.517378807067871, loss_D_A: 0.41550201177597046, loss_D_B: 0.16072432696819305 \n",
      "epoch: 4, loss G: 9.2338228225708, loss_G_identity: 2.1844429969787598, loss_G_GAN: 1.141271948814392, loss_G_cycle: 5.908107757568359, loss_D_A: 0.22912465035915375, loss_D_B: 0.22713422775268555 \n",
      "epoch: 4, loss G: 8.66160774230957, loss_G_identity: 2.4106836318969727, loss_G_GAN: 0.6155174374580383, loss_G_cycle: 5.635406494140625, loss_D_A: 0.3030778467655182, loss_D_B: 0.06250499188899994 \n",
      "epoch: 4, loss G: 8.801414489746094, loss_G_identity: 1.7809386253356934, loss_G_GAN: 0.8843106031417847, loss_G_cycle: 6.136165142059326, loss_D_A: 0.12473195046186447, loss_D_B: 0.1601119041442871 \n",
      "epoch: 4, loss G: 9.53542423248291, loss_G_identity: 1.619598627090454, loss_G_GAN: 1.3150423765182495, loss_G_cycle: 6.600783348083496, loss_D_A: 0.2558755874633789, loss_D_B: 0.1516173630952835 \n",
      "epoch: 4, loss G: 6.861852645874023, loss_G_identity: 1.711205005645752, loss_G_GAN: 0.5573950409889221, loss_G_cycle: 4.593252658843994, loss_D_A: 0.2385082244873047, loss_D_B: 0.01120085921138525 \n",
      "epoch: 4, loss G: 7.006867408752441, loss_G_identity: 1.372479796409607, loss_G_GAN: 0.43897712230682373, loss_G_cycle: 5.195410251617432, loss_D_A: 0.2721598148345947, loss_D_B: 0.0982326865196228 \n",
      "epoch: 4, loss G: 8.728784561157227, loss_G_identity: 1.5140310525894165, loss_G_GAN: 0.7009527087211609, loss_G_cycle: 6.513800621032715, loss_D_A: 0.17512036859989166, loss_D_B: 0.08766644448041916 \n",
      "epoch: 4, loss G: 10.31393814086914, loss_G_identity: 1.423427939414978, loss_G_GAN: 0.15901881456375122, loss_G_cycle: 8.731492042541504, loss_D_A: 0.27142736315727234, loss_D_B: 0.03795991465449333 \n",
      "epoch: 4, loss G: 8.780229568481445, loss_G_identity: 1.727927565574646, loss_G_GAN: 0.4094230830669403, loss_G_cycle: 6.642879486083984, loss_D_A: 0.15507425367832184, loss_D_B: 0.13071775436401367 \n",
      "epoch: 4, loss G: 8.82458209991455, loss_G_identity: 2.3966779708862305, loss_G_GAN: 0.4030187427997589, loss_G_cycle: 6.024885177612305, loss_D_A: 0.12611182034015656, loss_D_B: 0.03643544390797615 \n",
      "epoch: 4, loss G: 8.294454574584961, loss_G_identity: 1.464905858039856, loss_G_GAN: 1.66202974319458, loss_G_cycle: 5.167519569396973, loss_D_A: 0.3472028374671936, loss_D_B: 0.030379164963960648 \n",
      "epoch: 4, loss G: 9.507802963256836, loss_G_identity: 1.7237638235092163, loss_G_GAN: 1.1252903938293457, loss_G_cycle: 6.658748626708984, loss_D_A: 0.10688529908657074, loss_D_B: 0.08171190321445465 \n",
      "epoch: 4, loss G: 7.515171051025391, loss_G_identity: 1.8390114307403564, loss_G_GAN: 0.4638657867908478, loss_G_cycle: 5.21229362487793, loss_D_A: 0.014363905414938927, loss_D_B: 0.22288979589939117 \n",
      "epoch: 4, loss G: 8.422332763671875, loss_G_identity: 1.6681302785873413, loss_G_GAN: 0.8410424590110779, loss_G_cycle: 5.913159370422363, loss_D_A: 0.17298825085163116, loss_D_B: 0.08074063062667847 \n",
      "epoch: 4, loss G: 9.134855270385742, loss_G_identity: 0.972887396812439, loss_G_GAN: 0.6536710262298584, loss_G_cycle: 7.508297443389893, loss_D_A: 0.24732212722301483, loss_D_B: 0.1146332174539566 \n",
      "epoch: 4, loss G: 6.978091239929199, loss_G_identity: 1.4509625434875488, loss_G_GAN: 0.8637669682502747, loss_G_cycle: 4.663361549377441, loss_D_A: 0.22445839643478394, loss_D_B: 0.17006392776966095 \n",
      "epoch: 4, loss G: 8.329505920410156, loss_G_identity: 2.2271056175231934, loss_G_GAN: 0.29149365425109863, loss_G_cycle: 5.810906410217285, loss_D_A: 0.40226173400878906, loss_D_B: 0.2379564791917801 \n",
      "epoch: 4, loss G: 9.182464599609375, loss_G_identity: 1.5642825365066528, loss_G_GAN: 1.1028249263763428, loss_G_cycle: 6.51535701751709, loss_D_A: 0.22790727019309998, loss_D_B: 0.26504120230674744 \n",
      "epoch: 4, loss G: 7.224496364593506, loss_G_identity: 1.3492943048477173, loss_G_GAN: 0.7564865946769714, loss_G_cycle: 5.118715286254883, loss_D_A: 0.11558486521244049, loss_D_B: 0.12751519680023193 \n",
      "epoch: 4, loss G: 7.139848709106445, loss_G_identity: 1.448563814163208, loss_G_GAN: 0.3966168761253357, loss_G_cycle: 5.294668197631836, loss_D_A: 0.19887080788612366, loss_D_B: 0.21289612352848053 \n",
      "epoch: 4, loss G: 9.759748458862305, loss_G_identity: 2.3877151012420654, loss_G_GAN: 0.6410427093505859, loss_G_cycle: 6.730990409851074, loss_D_A: 0.5721570253372192, loss_D_B: 0.08565258234739304 \n",
      "epoch: 4, loss G: 11.71596908569336, loss_G_identity: 2.6269805431365967, loss_G_GAN: 0.590247392654419, loss_G_cycle: 8.498741149902344, loss_D_A: 0.3154682517051697, loss_D_B: 0.14010725915431976 \n",
      "epoch: 4, loss G: 8.606539726257324, loss_G_identity: 1.6332534551620483, loss_G_GAN: 1.0547969341278076, loss_G_cycle: 5.918489456176758, loss_D_A: 0.8541111946105957, loss_D_B: 0.2958741784095764 \n",
      "epoch: 4, loss G: 8.178556442260742, loss_G_identity: 1.5696290731430054, loss_G_GAN: 0.580070436000824, loss_G_cycle: 6.028857707977295, loss_D_A: 0.28101569414138794, loss_D_B: 0.19076208770275116 \n",
      "epoch: 4, loss G: 10.333695411682129, loss_G_identity: 1.955588698387146, loss_G_GAN: 1.0317190885543823, loss_G_cycle: 7.34638786315918, loss_D_A: 0.23100438714027405, loss_D_B: 0.22283554077148438 \n",
      "epoch: 4, loss G: 10.179832458496094, loss_G_identity: 2.524406909942627, loss_G_GAN: 0.7105939388275146, loss_G_cycle: 6.944831371307373, loss_D_A: 0.3142949938774109, loss_D_B: 0.01992248371243477 \n",
      "epoch: 4, loss G: 9.998658180236816, loss_G_identity: 2.145311117172241, loss_G_GAN: 0.9559911489486694, loss_G_cycle: 6.897356033325195, loss_D_A: 0.20828579366207123, loss_D_B: 0.008939795196056366 \n",
      "epoch: 4, loss G: 14.472856521606445, loss_G_identity: 2.123023271560669, loss_G_GAN: 1.263228416442871, loss_G_cycle: 11.086605072021484, loss_D_A: 0.27577298879623413, loss_D_B: 0.09824705868959427 \n",
      "epoch: 4, loss G: 9.855083465576172, loss_G_identity: 2.100421667098999, loss_G_GAN: 0.7478277087211609, loss_G_cycle: 7.006834506988525, loss_D_A: 0.3377092480659485, loss_D_B: 0.02863326668739319 \n",
      "epoch: 4, loss G: 8.86031436920166, loss_G_identity: 1.3354049921035767, loss_G_GAN: 0.6060547828674316, loss_G_cycle: 6.918854713439941, loss_D_A: 0.25576144456863403, loss_D_B: 0.07075047492980957 \n",
      "epoch: 4, loss G: 11.88700008392334, loss_G_identity: 2.5702106952667236, loss_G_GAN: 0.480058491230011, loss_G_cycle: 8.83673095703125, loss_D_A: 0.09705615788698196, loss_D_B: 0.3520206809043884 \n",
      "epoch: 4, loss G: 9.944971084594727, loss_G_identity: 1.492243766784668, loss_G_GAN: 0.7196184396743774, loss_G_cycle: 7.733109474182129, loss_D_A: 0.08738578855991364, loss_D_B: 0.11171852052211761 \n",
      "epoch: 4, loss G: 6.746675491333008, loss_G_identity: 1.13552725315094, loss_G_GAN: 0.5939977169036865, loss_G_cycle: 5.017150402069092, loss_D_A: 0.28956499695777893, loss_D_B: 0.04976050928235054 \n",
      "epoch: 4, loss G: 8.93648910522461, loss_G_identity: 1.7665613889694214, loss_G_GAN: 0.5762598514556885, loss_G_cycle: 6.593667984008789, loss_D_A: 0.33275628089904785, loss_D_B: 0.12893012166023254 \n",
      "epoch: 4, loss G: 9.190936088562012, loss_G_identity: 1.63340425491333, loss_G_GAN: 1.0216562747955322, loss_G_cycle: 6.5358757972717285, loss_D_A: 0.09910835325717926, loss_D_B: 0.11830714344978333 \n",
      "epoch: 4, loss G: 7.784670352935791, loss_G_identity: 1.5107142925262451, loss_G_GAN: 0.3671554625034332, loss_G_cycle: 5.906800270080566, loss_D_A: 0.3320668935775757, loss_D_B: 0.172504261136055 \n",
      "epoch: 4, loss G: 6.583154678344727, loss_G_identity: 1.345969557762146, loss_G_GAN: 1.3417223691940308, loss_G_cycle: 3.89546275138855, loss_D_A: 0.11682379245758057, loss_D_B: 0.09511085599660873 \n",
      "epoch: 4, loss G: 9.097497940063477, loss_G_identity: 2.322601318359375, loss_G_GAN: 0.609324038028717, loss_G_cycle: 6.1655731201171875, loss_D_A: 0.1723840832710266, loss_D_B: 0.34040921926498413 \n",
      "epoch: 4, loss G: 11.101423263549805, loss_G_identity: 2.3079261779785156, loss_G_GAN: 0.9506422281265259, loss_G_cycle: 7.8428544998168945, loss_D_A: 0.15861862897872925, loss_D_B: 0.03766437619924545 \n",
      "epoch: 4, loss G: 14.997695922851562, loss_G_identity: 1.8726871013641357, loss_G_GAN: 1.4096856117248535, loss_G_cycle: 11.715323448181152, loss_D_A: 0.19965317845344543, loss_D_B: 0.15956735610961914 \n",
      "epoch: 4, loss G: 7.93597412109375, loss_G_identity: 1.591423749923706, loss_G_GAN: 0.9125098586082458, loss_G_cycle: 5.432040214538574, loss_D_A: 0.1705564260482788, loss_D_B: 0.09026028215885162 \n",
      "epoch: 4, loss G: 9.877154350280762, loss_G_identity: 1.879551887512207, loss_G_GAN: 0.4723202586174011, loss_G_cycle: 7.525282382965088, loss_D_A: 0.31672847270965576, loss_D_B: 0.12806503474712372 \n",
      "epoch: 4, loss G: 10.173667907714844, loss_G_identity: 2.0348548889160156, loss_G_GAN: 0.9397141337394714, loss_G_cycle: 7.199098587036133, loss_D_A: 0.32457852363586426, loss_D_B: 0.22894352674484253 \n",
      "epoch: 4, loss G: 6.979580879211426, loss_G_identity: 1.7643386125564575, loss_G_GAN: 0.668672502040863, loss_G_cycle: 4.54656982421875, loss_D_A: 0.4254663586616516, loss_D_B: 0.045136820524930954 \n",
      "epoch: 4, loss G: 8.627117156982422, loss_G_identity: 2.025953769683838, loss_G_GAN: 0.6559145450592041, loss_G_cycle: 5.945248603820801, loss_D_A: 0.2072410136461258, loss_D_B: 0.1736956238746643 \n",
      "epoch: 4, loss G: 13.952265739440918, loss_G_identity: 3.189281940460205, loss_G_GAN: 0.6106652021408081, loss_G_cycle: 10.152318954467773, loss_D_A: 0.10655339062213898, loss_D_B: 0.1092277318239212 \n",
      "epoch: 4, loss G: 9.276817321777344, loss_G_identity: 1.939846158027649, loss_G_GAN: 0.9967440366744995, loss_G_cycle: 6.340226650238037, loss_D_A: 0.3244619369506836, loss_D_B: 0.21876676380634308 \n",
      "epoch: 4, loss G: 9.314209938049316, loss_G_identity: 1.490190029144287, loss_G_GAN: 0.9669780135154724, loss_G_cycle: 6.85704231262207, loss_D_A: 0.17663756012916565, loss_D_B: 0.03243635967373848 \n",
      "epoch: 4, loss G: 7.6205339431762695, loss_G_identity: 1.791756510734558, loss_G_GAN: 0.9941128492355347, loss_G_cycle: 4.834664344787598, loss_D_A: 0.0934755951166153, loss_D_B: 0.005645712837576866 \n",
      "epoch: 4, loss G: 8.439064025878906, loss_G_identity: 1.5964359045028687, loss_G_GAN: 0.5677781105041504, loss_G_cycle: 6.274849891662598, loss_D_A: 0.561713457107544, loss_D_B: 0.13185074925422668 \n",
      "epoch: 4, loss G: 12.890975952148438, loss_G_identity: 2.5033931732177734, loss_G_GAN: 0.7786250114440918, loss_G_cycle: 9.608957290649414, loss_D_A: 0.27334922552108765, loss_D_B: 0.09116988629102707 \n",
      "epoch: 4, loss G: 10.217905044555664, loss_G_identity: 1.8753536939620972, loss_G_GAN: 0.19678723812103271, loss_G_cycle: 8.145763397216797, loss_D_A: 0.4261193871498108, loss_D_B: 0.04739203304052353 \n",
      "epoch: 4, loss G: 8.40678596496582, loss_G_identity: 2.2348713874816895, loss_G_GAN: 0.5487388968467712, loss_G_cycle: 5.623175621032715, loss_D_A: 0.11832530796527863, loss_D_B: 0.2768377363681793 \n",
      "epoch: 4, loss G: 7.530467987060547, loss_G_identity: 1.476291298866272, loss_G_GAN: 1.005636215209961, loss_G_cycle: 5.048540115356445, loss_D_A: 0.4329789876937866, loss_D_B: 0.04411575198173523 \n",
      "epoch: 4, loss G: 11.410947799682617, loss_G_identity: 2.3856868743896484, loss_G_GAN: 1.2594082355499268, loss_G_cycle: 7.765852928161621, loss_D_A: 0.3751697540283203, loss_D_B: 0.12786874175071716 \n",
      "epoch: 4, loss G: 11.93211841583252, loss_G_identity: 2.658830165863037, loss_G_GAN: 0.9351688623428345, loss_G_cycle: 8.338119506835938, loss_D_A: 0.13906289637088776, loss_D_B: 0.052483946084976196 \n",
      "epoch: 4, loss G: 10.290252685546875, loss_G_identity: 2.037045478820801, loss_G_GAN: 0.8704596757888794, loss_G_cycle: 7.382747173309326, loss_D_A: 0.265433132648468, loss_D_B: 0.1470591425895691 \n",
      "epoch: 4, loss G: 7.353296756744385, loss_G_identity: 1.2264025211334229, loss_G_GAN: 1.2433221340179443, loss_G_cycle: 4.883572101593018, loss_D_A: 0.04194556176662445, loss_D_B: 0.01615302823483944 \n",
      "epoch: 4, loss G: 7.968450546264648, loss_G_identity: 1.8476266860961914, loss_G_GAN: 0.9652377367019653, loss_G_cycle: 5.155586242675781, loss_D_A: 0.3019106388092041, loss_D_B: 0.07780686020851135 \n",
      "epoch: 4, loss G: 7.06073522567749, loss_G_identity: 1.8816450834274292, loss_G_GAN: 1.05255925655365, loss_G_cycle: 4.12653112411499, loss_D_A: 0.12405140697956085, loss_D_B: 0.06906283646821976 \n",
      "epoch: 4, loss G: 11.855379104614258, loss_G_identity: 2.9350857734680176, loss_G_GAN: 0.7234009504318237, loss_G_cycle: 8.196891784667969, loss_D_A: 0.0638885647058487, loss_D_B: 0.15431854128837585 \n",
      "epoch: 4, loss G: 7.001657485961914, loss_G_identity: 1.6450356245040894, loss_G_GAN: 1.1591570377349854, loss_G_cycle: 4.197464942932129, loss_D_A: 0.175257608294487, loss_D_B: 0.006855937652289867 \n",
      "epoch: 4, loss G: 9.652521133422852, loss_G_identity: 2.0824086666107178, loss_G_GAN: 1.68532133102417, loss_G_cycle: 5.884791374206543, loss_D_A: 0.132843017578125, loss_D_B: 0.030333446338772774 \n",
      "epoch: 4, loss G: 5.836093425750732, loss_G_identity: 1.531754732131958, loss_G_GAN: 0.407865047454834, loss_G_cycle: 3.8964736461639404, loss_D_A: 0.30698126554489136, loss_D_B: 0.3425011932849884 \n",
      "epoch: 4, loss G: 8.23196029663086, loss_G_identity: 1.672368049621582, loss_G_GAN: 1.1231828927993774, loss_G_cycle: 5.436409950256348, loss_D_A: 0.2546866536140442, loss_D_B: 0.08304016292095184 \n",
      "epoch: 4, loss G: 8.350889205932617, loss_G_identity: 1.3003343343734741, loss_G_GAN: 0.6072989702224731, loss_G_cycle: 6.443255424499512, loss_D_A: 0.372406542301178, loss_D_B: 0.11685068905353546 \n",
      "epoch: 4, loss G: 8.753395080566406, loss_G_identity: 2.4171695709228516, loss_G_GAN: 0.8414522409439087, loss_G_cycle: 5.494772911071777, loss_D_A: 0.195989191532135, loss_D_B: 0.057337336242198944 \n",
      "epoch: 4, loss G: 9.508271217346191, loss_G_identity: 1.8966302871704102, loss_G_GAN: 1.1545573472976685, loss_G_cycle: 6.457083702087402, loss_D_A: 0.11623256653547287, loss_D_B: 0.09399978816509247 \n",
      "epoch: 4, loss G: 10.203654289245605, loss_G_identity: 1.6253318786621094, loss_G_GAN: 0.5841379165649414, loss_G_cycle: 7.994184494018555, loss_D_A: 0.22593152523040771, loss_D_B: 0.12116412818431854 \n",
      "epoch: 4, loss G: 10.013422966003418, loss_G_identity: 1.4968936443328857, loss_G_GAN: 0.4478048086166382, loss_G_cycle: 8.068724632263184, loss_D_A: 0.3027467727661133, loss_D_B: 0.28551730513572693 \n",
      "epoch: 4, loss G: 9.848901748657227, loss_G_identity: 2.5859272480010986, loss_G_GAN: 0.7074694037437439, loss_G_cycle: 6.55550479888916, loss_D_A: 0.20193026959896088, loss_D_B: 0.027686400339007378 \n",
      "epoch: 4, loss G: 11.22753620147705, loss_G_identity: 1.4097115993499756, loss_G_GAN: 1.1873208284378052, loss_G_cycle: 8.63050365447998, loss_D_A: 0.1969253420829773, loss_D_B: 0.032882265746593475 \n",
      "epoch: 4, loss G: 8.822919845581055, loss_G_identity: 1.8575522899627686, loss_G_GAN: 1.3358983993530273, loss_G_cycle: 5.62946891784668, loss_D_A: 0.13027042150497437, loss_D_B: 0.14670512080192566 \n",
      "epoch: 4, loss G: 5.844644546508789, loss_G_identity: 1.3178532123565674, loss_G_GAN: 0.25315192341804504, loss_G_cycle: 4.27363920211792, loss_D_A: 0.43068963289260864, loss_D_B: 0.38802570104599 \n",
      "epoch: 4, loss G: 10.123838424682617, loss_G_identity: 2.141181707382202, loss_G_GAN: 0.4283592104911804, loss_G_cycle: 7.554298400878906, loss_D_A: 0.5135135054588318, loss_D_B: 0.07959970831871033 \n",
      "epoch: 4, loss G: 8.957780838012695, loss_G_identity: 1.4613425731658936, loss_G_GAN: 0.5017401576042175, loss_G_cycle: 6.994697570800781, loss_D_A: 0.263313889503479, loss_D_B: 0.007132533937692642 \n",
      "epoch: 4, loss G: 9.539115905761719, loss_G_identity: 1.7617273330688477, loss_G_GAN: 0.7504838705062866, loss_G_cycle: 7.026904106140137, loss_D_A: 0.286975622177124, loss_D_B: 0.1194363385438919 \n",
      "epoch: 4, loss G: 11.376029968261719, loss_G_identity: 2.53049373626709, loss_G_GAN: 0.753545880317688, loss_G_cycle: 8.09199047088623, loss_D_A: 0.20148435235023499, loss_D_B: 0.05917445570230484 \n",
      "epoch: 4, loss G: 9.12160587310791, loss_G_identity: 2.1352601051330566, loss_G_GAN: 1.3185566663742065, loss_G_cycle: 5.667788505554199, loss_D_A: 0.04435276612639427, loss_D_B: 0.03670979291200638 \n",
      "epoch: 4, loss G: 10.381332397460938, loss_G_identity: 2.115497350692749, loss_G_GAN: 0.7189140319824219, loss_G_cycle: 7.5469207763671875, loss_D_A: 0.21175900101661682, loss_D_B: 0.13420571386814117 \n",
      "epoch: 4, loss G: 8.845230102539062, loss_G_identity: 1.4300365447998047, loss_G_GAN: 1.075382113456726, loss_G_cycle: 6.339811325073242, loss_D_A: 0.22978469729423523, loss_D_B: 0.027955641970038414 \n",
      "epoch: 4, loss G: 8.259507179260254, loss_G_identity: 1.6568899154663086, loss_G_GAN: 2.7937099933624268, loss_G_cycle: 3.8089075088500977, loss_D_A: 0.32976216077804565, loss_D_B: 0.12509891390800476 \n",
      "epoch: 4, loss G: 10.383262634277344, loss_G_identity: 1.9721941947937012, loss_G_GAN: 1.6221587657928467, loss_G_cycle: 6.788909912109375, loss_D_A: 0.1772957146167755, loss_D_B: 0.07663403451442719 \n",
      "epoch: 4, loss G: 7.220749855041504, loss_G_identity: 1.3752357959747314, loss_G_GAN: 1.4326181411743164, loss_G_cycle: 4.412896156311035, loss_D_A: 0.2043285071849823, loss_D_B: 0.001564658829011023 \n",
      "epoch: 4, loss G: 8.426541328430176, loss_G_identity: 1.6580907106399536, loss_G_GAN: 1.033179521560669, loss_G_cycle: 5.735270977020264, loss_D_A: 0.4058294892311096, loss_D_B: 0.169877290725708 \n",
      "epoch: 4, loss G: 7.70073938369751, loss_G_identity: 1.6441385746002197, loss_G_GAN: 0.8173853158950806, loss_G_cycle: 5.239214897155762, loss_D_A: 0.21704910695552826, loss_D_B: 0.21408352255821228 \n",
      "epoch: 4, loss G: 10.91362190246582, loss_G_identity: 2.5607073307037354, loss_G_GAN: 0.3948376178741455, loss_G_cycle: 7.9580769538879395, loss_D_A: 0.326663613319397, loss_D_B: 0.11474931985139847 \n",
      "epoch: 4, loss G: 8.884468078613281, loss_G_identity: 2.2781922817230225, loss_G_GAN: 1.4741463661193848, loss_G_cycle: 5.132128715515137, loss_D_A: 0.10412320494651794, loss_D_B: 0.08923392742872238 \n",
      "epoch: 4, loss G: 11.059819221496582, loss_G_identity: 1.8409329652786255, loss_G_GAN: 0.39862197637557983, loss_G_cycle: 8.82026481628418, loss_D_A: 0.21013620495796204, loss_D_B: 0.21734367311000824 \n",
      "epoch: 4, loss G: 9.795491218566895, loss_G_identity: 2.146200180053711, loss_G_GAN: 1.3402843475341797, loss_G_cycle: 6.309006690979004, loss_D_A: 0.17397531867027283, loss_D_B: 0.019075285643339157 \n",
      "epoch: 4, loss G: 9.963180541992188, loss_G_identity: 1.5814497470855713, loss_G_GAN: 2.1031551361083984, loss_G_cycle: 6.278575897216797, loss_D_A: 0.22191812098026276, loss_D_B: 0.2778824269771576 \n",
      "epoch: 4, loss G: 10.222594261169434, loss_G_identity: 1.5899555683135986, loss_G_GAN: 1.3031611442565918, loss_G_cycle: 7.329477310180664, loss_D_A: 0.17616111040115356, loss_D_B: 0.02691076509654522 \n",
      "epoch: 4, loss G: 11.29466438293457, loss_G_identity: 2.3796334266662598, loss_G_GAN: 0.801689863204956, loss_G_cycle: 8.113341331481934, loss_D_A: 0.07444038987159729, loss_D_B: 0.057083263993263245 \n",
      "epoch: 4, loss G: 7.478998184204102, loss_G_identity: 2.015296697616577, loss_G_GAN: 0.5839899778366089, loss_G_cycle: 4.879712104797363, loss_D_A: 0.1859835535287857, loss_D_B: 0.1631879061460495 \n",
      "epoch: 4, loss G: 8.175297737121582, loss_G_identity: 1.8348166942596436, loss_G_GAN: 0.9557170867919922, loss_G_cycle: 5.384763717651367, loss_D_A: 0.365228533744812, loss_D_B: 0.04733598977327347 \n",
      "epoch: 4, loss G: 9.542417526245117, loss_G_identity: 2.652418613433838, loss_G_GAN: 0.7102459669113159, loss_G_cycle: 6.179752349853516, loss_D_A: 0.22202786803245544, loss_D_B: 0.027332492172718048 \n",
      "epoch: 4, loss G: 9.74494743347168, loss_G_identity: 2.230701446533203, loss_G_GAN: 1.803839921951294, loss_G_cycle: 5.710405349731445, loss_D_A: 0.1496008187532425, loss_D_B: 0.10162881761789322 \n",
      "epoch: 4, loss G: 11.699833869934082, loss_G_identity: 2.206479549407959, loss_G_GAN: 1.016967535018921, loss_G_cycle: 8.476387023925781, loss_D_A: 0.2914842963218689, loss_D_B: 0.12049154192209244 \n",
      "epoch: 4, loss G: 8.218467712402344, loss_G_identity: 1.2424906492233276, loss_G_GAN: 1.378492832183838, loss_G_cycle: 5.5974836349487305, loss_D_A: 0.1717592030763626, loss_D_B: 0.0027804735582321882 \n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-2e9cd4cd158f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m                         \u001b[0mloss_GAN_A2B\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0mloss_GAN_B2A\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_Cycle_ABA\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_Cycle_BAB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mloss_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mopt_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i,batch in enumerate(dataloader):\n",
    "        real_A = torch.tensor(input_A.copy_(batch[\"A\"]), dtype = torch.float).to(device)\n",
    "        real_B = torch.tensor(input_B.copy_(batch[\"B\"]), dtype = torch.float).to(device)\n",
    "\n",
    "        opt_G.zero_grad()\n",
    "        same_B = netG_A2B(real_B)  # 生成器A2B生成B\n",
    "        loss_identity_B = loss_identity(same_B, real_B) * 5.0 # 生成的B和真实B的差别 B是橘子\n",
    "\n",
    "        same_A = netG_B2A(real_A)\n",
    "        loss_identity_A = loss_identity(same_A, real_A) * 5.0\n",
    "\n",
    "        fake_B = netG_A2B(real_A)   # 苹果生成假橘子\n",
    "        pred_fake = netD_B(fake_B)   # 判别器给生成器生成的B打分\n",
    "        loss_GAN_A2B = loss_GAN(pred_fake, label_real)        \n",
    "\n",
    "\n",
    "        fake_A = netG_B2A(real_B)\n",
    "        pred_fake = netD_A(fake_A)\n",
    "        loss_GAN_B2A = loss_GAN(pred_fake, label_real)\n",
    "\n",
    "        # cycle loss\n",
    "        recover_A = netG_B2A(fake_B)\n",
    "        loss_Cycle_ABA = loss_Cycle(recover_A, real_A)  * 10.0\n",
    "\n",
    "        recover_B = netG_A2B(fake_A)\n",
    "        loss_Cycle_BAB = loss_Cycle(recover_B, real_B)  * 10.0\n",
    "\n",
    "        loss_G = loss_identity_B + loss_identity_A + \\\n",
    "                        loss_GAN_A2B +  loss_GAN_B2A + loss_Cycle_ABA + loss_Cycle_BAB\n",
    "\n",
    "        loss_G.backward()\n",
    "\n",
    "        opt_G.step()\n",
    "\n",
    "        ############################### 判别器 #################################\n",
    "\n",
    "        optD_A.zero_grad()\n",
    "\n",
    "        pred_real = netD_A(real_A)\n",
    "        loss_D_real = loss_GAN(pred_real, label_real)\n",
    "        fake_A = fake_A_buffer.push_and_pop(fake_A)   # 放入队列中，再从队列中随机选一个当做fake_A\n",
    "        pred_fake = netD_A(fake_A.detach())  # fake_A由生成器产生，避免更新判别器的时候对生成器参数更新，加入detach  梯度截断\n",
    "\n",
    "        loss_D_fake = loss_GAN(pred_fake, label_fake)  \n",
    "        loss_D_A = (loss_D_real + loss_D_fake) * 0.5\n",
    "        \n",
    "\n",
    "        loss_D_A.backward()\n",
    "        optD_A.step()\n",
    "\n",
    "        ## B--->\n",
    "        optD_B.zero_grad()\n",
    "        pred_real = netD_B(real_B)\n",
    "        loss_D_real = loss_GAN(pred_real, label_real)\n",
    "\n",
    "        fake_B = fake_B_buffer.push_and_pop(fake_B)\n",
    "        pred_fake = netD_B(fake_B.detach())\n",
    "        loss_D_fake = loss_GAN(pred_fake, label_fake)\n",
    "\n",
    "        loss_D_B = (loss_D_real + loss_D_fake) * 0.5\n",
    "        loss_D_B.backward()\n",
    "        optD_B.step()\n",
    "\n",
    "        print(\"epoch: {}, loss G: {}, loss_G_identity: {}, loss_G_GAN: {}, loss_G_cycle: {}, loss_D_A: {}, loss_D_B: {} \"\\\n",
    "                .format(epoch,\n",
    "                        loss_G, \n",
    "                        loss_identity_A+loss_identity_B, \n",
    "                        loss_GAN_A2B+loss_GAN_B2A, \n",
    "                        loss_Cycle_ABA + loss_Cycle_BAB,\n",
    "                        loss_D_A,\n",
    "                        loss_D_B))\n",
    "        write_log.add_scalar(\"loss_G\", loss_G, global_step=step + 1)\n",
    "        write_log.add_scalar(\"loss_G_identity\", loss_identity_A+loss_identity_B, global_step=step + 1)\n",
    "        write_log.add_scalar(\"loss_G_GAN\",  loss_GAN_A2B+loss_GAN_B2A, global_step=step + 1)\n",
    "        write_log.add_scalar(\"loss_G_cycle\", loss_Cycle_ABA + loss_Cycle_BAB, global_step=step + 1)\n",
    "        write_log.add_scalar(\"loss_D_A\", loss_D_A, global_step=step + 1)\n",
    "        write_log.add_scalar(\"loss_D_B\", loss_D_B, global_step=step + 1)\n",
    "\n",
    "        step += 1\n",
    "    \n",
    "    # 更新学习率\n",
    "    lr_scheduler_G.step()\n",
    "    lr_scheduler_D_A.step()\n",
    "    lr_scheduler_D_B.step()\n",
    "\n",
    "    torch.save(netG_A2B.state_dict(), \"/data/zhuowei_common/models/cyclegan/netG_A2B.pth\")\n",
    "    torch.save(netG_B2A.state_dict(), \"/data/zhuowei_common/models/cyclegan/netG_B2A.pth\")\n",
    "    torch.save(netD_A.state_dict(), \"/data/zhuowei_common/models/cyclegan/netD_A.pth\")\n",
    "    torch.save(netD_B.state_dict(), \"/data/zhuowei_common/models/cyclegan/netD_B.pth\")"
   ]
  },
  {
   "source": [
    "# Test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as trForms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "netG_A2B = Generator().to(device)\n",
    "netG_B2A = Generator().to(device)\n",
    "\n",
    "netG_A2B.load_state_dict(torch.load(\"/data/zhuowei_common/models/cyclegan/netG_A2B.pth\"))\n",
    "netG_B2A.load_state_dict(torch.load(\"/data/zhuowei_common/models/cyclegan/netG_B2A.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG_A2B.eval()\n",
    "netG_B2A.eval()\n",
    "\n",
    "size = 256\n",
    "\n",
    "input_A = torch.ones([1,3,size, size], dtype=torch.float).to(device)\n",
    "\n",
    "input_B = torch.ones([1,3,size, size], dtype=torch.float).to(device)\n",
    "\n",
    "transforms_ = [\n",
    "    trForms.ToTensor(),\n",
    "    trForms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "]\n",
    "\n",
    "\n",
    "data_root = \"/data/zhuowei/datasets/cyclegan/datasets/apple2orange\"\n",
    "\n",
    "dataloader = DataLoader(ImageDataset(root = data_root,transform = transforms_, model = \"test\"), batch_size = 1, shuffle = False, num_workers = 8)\n",
    "\n",
    "if not os.path.exists(\"/data/zhuowei_common/output/cyclegan/A\"):\n",
    "    os.mkdir(\"/data/zhuowei_common/output/cyclegan/A\")\n",
    "if not os.path.exists(\"/data/zhuowei_common/output/cyclegan/B\"):\n",
    "    os.mkdir(\"/data/zhuowei_common/output/cyclegan/B\")\n",
    "\n",
    "for i, batch in enumerate(dataloader):\n",
    "    real_A = torch.tensor(input_A.copy_(batch[\"A\"]), dtype = torch.float).to(device)\n",
    "    real_B = torch.tensor(input_B.copy_(batch[\"A\"]), dtype = torch.float).to(device)\n",
    "\n",
    "    fake_B = 0.5 * (netG_A2B(real_A).data + 1.0)\n",
    "\n",
    "    fake_A = 0.5 * (netG_B2A(real_B).data + 1.0)\n",
    "\n",
    "    save_image(fake_A, \"/data/zhuowei_common/output/cyclegan/A/{}.png\".format(i))\n",
    "    save_image(fake_B, \"/data/zhuowei_common/output/cyclegan/B/{}.png\".format(i))\n",
    "    print(i)"
   ]
  }
 ]
}